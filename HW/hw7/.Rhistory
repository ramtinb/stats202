test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
matpoints(x=which.min(test.err), y=test.err[which.min(test.err)], col="green", pch=20)
matpoints(x=which.min(train.err), y=train.err[which.min(train.err)], col="green", pch=20)
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
matpoints(x=c(which.min(test.err), which.min(train.err)) , y=c(test.err[which.min(test.err)],train.err[which.min(train.err)]), col="green", pch=20)
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
c(which.min(test.err), which.min(train.err)
)
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambds(which.min(test.err))
(which.min(test.err)
)
lambds(which.min(test.err))
minTest = lambds[which.min(test.err)]
minTest = lambdas[which.min(test.err)]
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
matpoints(x=c(minTest,mintTrain) , y=c(test.err[minTest],train.err[mintTrain]), col="green", pch=20)
minTest
mintTrain
test.err[minTest]
test.err[minTest][1]
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
matpoints(x=c(minTest,mintTrain) , y=c(test.err[which.min(test.err)],train.err[which.min(train.err)]), col="green", pch=20)
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
test.err[minTest]
minTest
test.err[which.min(test.err)]
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
matpoints(x=c(minTest,mintTrain) , y=c(test.err[which.min(test.err)],train.err[which.min(train.err)]), col=c("green","green, pch=20)
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
matpoints(x=c(minTest,mintTrain) , y=c(test.err[which.min(test.err)],train.err[which.min(train.err)]), col=c("green","green", pch=20)
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
matpoints(x=c(minTest,mintTrain) , y=c(test.err[which.min(test.err)],train.err[which.min(train.err)]), col=c("green","green"), pch=20)
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
matpoints(x=c(minTest,mintTrain) , y=c(test.err[which.min(test.err)],train.err[which.min(train.err)]), col=c("green","black"), pch=30)
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
#plot(lambdas, train.err, pch=19, type="b" )
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
matpoints(x=c(minTest,mintTrain) , y=c(test.err[which.min(test.err)],train.err[which.min(train.err)]), col=c("green","black"), pch=20)
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
cat("best lambda for Test error ", lambdas[which.min(test.err)])
cat("best lambda for train error ", lambdas[which.min(train.err)])
cat("best lambda for Test error ", lambdas[which.min(test.err)])
cat("best lambda for train error ", lambdas[which.min(train.err)])
cat("best lambda for Test error ", lambdas[which.min(test.err)])
cat("\n")
cat("best lambda for train error ", lambdas[which.min(train.err)])
cat("best lambda for Test error ", which.min(test.err))
cat("\n")
cat("best lambda for train error ", lambdas[which.min(train.err)])
cat("Test error ", min(test.err))
cat("\n")
cat("Train error ", min(train.err))
cat("Test error ", min(test.err))
cat("\n")
cat("lambda for Test error ", lambdas[which.min(test.err)])
cat("\n")
cat("Train error ", min(train.err))
cat("\n")
cat("lambda for Train error ", lambdas[which.min(train.err)])
cat("Test error ", min(test.err))
cat("\n")
cat("lambda for Test error ", lambdas[which.min(test.err)])
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
cat("Test error ", min(test.err))
cat("\n")
cat("lambda for Test error ", lambdas[which.min(test.err)])
lm.fit =  lm.fit(Salary ~., data=Hitters, subset=train)
lm.fit =  lm.fit(Salary ~., data=Hitters, subset=train)
lm.fit =  lm.fit(Salary ~., data=Hitters[train,])
lm.fit =  lm(Salary ~., data=Hitters[train,])
lm.pred = predict(lm.fit, Hitters[-train,])
lm.err = mean((Hitters[-train,"Salary"]-lm.pred)^2)
lm.err
require(tree)
require(ISLR)
attach(Carseats)
set.seed(1)
train = sample(nrow(Carseats), nrow(Carseats)/2)
tree.carseats = tree(Sales ~., data = Carseats[train,])
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0)
tree.pred = predict(tree.carseats, newdata = Carseats[-train,])
tree.err = with(Carseats[-train,],  mean((Sales-tree.pred)^2))
tree.err
set.seed(1)
cv.carseats = cv.tree(tree.carseats, FUN = prune.tree)
plot(cv.carseats)
prune.carseats = prune.tree(tree.carseats, best = 10)
plot(prune.carseats)
text(prune.carseats)
prune.predicts = predict(prune.carseats, newdata = Carseats[-train,])
prune.err =  with(Carseats[-train,], mean((Sales - prune.predicts)^2))
prune.err
require(randomForest)
bag.carseats = randomForest(Sales ~., data = Carseats, subset = train, mtry=10, ntree=1000, importance=TRUE)
bag.predict = predict(bag.carseats, Carseats[-train,])
importance(bag.carseats)
mean((Carseats[-train,"Sales"]-bag.predict)^2)
varImpPlot(bag.carseats)
test.err = double(10)
for (mtry in 1:10){
fit = randomForest(Sales ~., data = Carseats, subset = train, mtry=mtry, ntree=1000, importance=TRUE)
obb.err = fit$mse[1000]
pred = predict(fit, Carseats[-train,])
test.err[mtry] = with(Carseats[-train,], mean((Sales-pred)^2))
}
plot(test.err, type = "b")
points(y=test.err[which.min(test.err)], x=which.min(test.err), col="yellow", pch=20)
points(y=test.err[4], x=4, col="red", pch=20)
rf.carseats = randomForest(Sales ~., data = Carseats, subset = train, mtry=4, ntree=1000, importance=TRUE)
varImpPlot(rf.carseats)
importance(rf.carseats)
test.err[4]
require(gbm)
require(glmnet)
attach(Hitters)
nrow(Hitters)
Hitters = Hitters[-which(is.na(Hitters$Salary)),]
nrow(Hitters)
Hitters$Salary = log(Hitters$Salary)
train = sample(nrow(Hitters), nrow(Hitters)/2)
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
require(tree)
require(ISLR)
attach(Carseats)
set.seed(1)
train = sample(nrow(Carseats), nrow(Carseats)/2)
tree.carseats = tree(Sales ~., data = Carseats[train,])
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats, pretty = 0)
tree.pred = predict(tree.carseats, newdata = Carseats[-train,])
tree.err = with(Carseats[-train,],  mean((Sales-tree.pred)^2))
tree.err
set.seed(1)
cv.carseats = cv.tree(tree.carseats, FUN = prune.tree)
plot(cv.carseats)
prune.carseats = prune.tree(tree.carseats, best = 10)
plot(prune.carseats)
text(prune.carseats)
prune.predicts = predict(prune.carseats, newdata = Carseats[-train,])
prune.err =  with(Carseats[-train,], mean((Sales - prune.predicts)^2))
prune.err
require(randomForest)
bag.carseats = randomForest(Sales ~., data = Carseats, subset = train, mtry=10, ntree=1000, importance=TRUE)
bag.predict = predict(bag.carseats, Carseats[-train,])
importance(bag.carseats)
mean((Carseats[-train,"Sales"]-bag.predict)^2)
varImpPlot(bag.carseats)
test.err = double(10)
for (mtry in 1:10){
fit = randomForest(Sales ~., data = Carseats, subset = train, mtry=mtry, ntree=1000, importance=TRUE)
obb.err = fit$mse[1000]
pred = predict(fit, Carseats[-train,])
test.err[mtry] = with(Carseats[-train,], mean((Sales-pred)^2))
}
plot(test.err, type = "b")
points(y=test.err[which.min(test.err)], x=which.min(test.err), col="yellow", pch=20)
points(y=test.err[4], x=4, col="red", pch=20)
rf.carseats = randomForest(Sales ~., data = Carseats, subset = train, mtry=4, ntree=1000, importance=TRUE)
varImpPlot(rf.carseats)
importance(rf.carseats)
test.err[4]
require(gbm)
require(glmnet)
attach(Hitters)
nrow(Hitters)
Hitters = Hitters[-which(is.na(Hitters$Salary)),]
nrow(Hitters)
Hitters$Salary = log(Hitters$Salary)
train = sample(nrow(Hitters), nrow(Hitters)/2)
lambdas = 10^ (seq(from=-10, to=-0.1, by=0.1))
train.err = rep(NA, length(lambdas))
test.err = rep(NA, length(lambdas))
for (l in 1:length(lambdas)){
boost.hitters = gbm(Salary ~., data=Hitters[train,], distribution="gaussian", n.trees = 1000, shrinkage=lambdas[l], interaction.depth = 1)
train.pred = predict(boost.hitters, Hitters[train,], n.trees = 1000)
test.pred = predict(boost.hitters, Hitters[-train,], n.trees = 1000)
train.err[l] = with(Hitters[train,], mean((Salary-train.pred)^2))
test.err[l] = with(Hitters[-train,], mean((Salary-test.pred)^2))
}
matplot(lambdas, cbind(test.err,train.err ), pch=19, col=c("red","blue"), type="b" )
minTest = lambdas[which.min(test.err)]
mintTrain = lambdas[which.min(train.err)]
legend("topright", legend = c("test","train"), col=c("red","blue"), pch=19)
cat("Test error ", min(test.err))
cat("\n")
cat("lambda for Test error ", lambdas[which.min(test.err)])
lm.fit =  lm(Salary ~., data=Hitters[train,])
lm.pred = predict(lm.fit, Hitters[-train,])
lm.err = mean((Hitters[-train,"Salary"]-lm.pred)^2)
lm.err
x.train = model.matrix(Salary ~. , data = Hitters[train,])
y = Hitters[train, "Salary"]
x.test = model.matrix(Salary ~. , data = Hitters[-train,])
lasso.fit = glmnet(x,y)
x.train = model.matrix(Salary ~. , data = Hitters[train,])
y = Hitters[train, "Salary"]
x.test = model.matrix(Salary ~. , data = Hitters[-train,])
lasso.fit = glmnet(x.train, y)
x.train = model.matrix(Salary ~. , data = Hitters[train,])
y = Hitters[train, "Salary"]
x.test = model.matrix(Salary ~. , data = Hitters[-train,])
lasso.fit = glmnet(x.train, y)
lasso.pred = predict(lasso.fit, newx = x.test)
x.train = model.matrix(Salary ~. , data = Hitters[train,])
y = Hitters[train, "Salary"]
x.test = model.matrix(Salary ~. , data = Hitters[-train,])
lasso.fit = glmnet(x.train, y)
lasso.pred = predict(lasso.fit, newx = x.test)
lasso.err = mean((Hitters[-train,"Salary"]-lasso.pred)^2)
lasso.err
cat("Test error ", min(test.err))
cat("\n")
cat("lambda for Test error ", lambdas[which.min(test.err)])
lm.fit =  lm(Salary ~., data=Hitters[train,])
lm.pred = predict(lm.fit, Hitters[-train,])
lm.err = mean((Hitters[-train,"Salary"]-lm.pred)^2)
lm.err
x.train = model.matrix(Salary ~. , data = Hitters[train,])
y = Hitters[train, "Salary"]
x.test = model.matrix(Salary ~. , data = Hitters[-train,])
lasso.fit = glmnet(x.train, y)
lasso.pred = predict(lasso.fit, newx = x.test)
lasso.err = mean((Hitters[-train,"Salary"]-lasso.pred)^2)
lasso.err
boost.fit = gbm(Salary~., data=Hitters[train,], distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[which.min(test.err)], importance=TRUE)
boost.fit = gbm(Salary~., data=Hitters[train,], distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[which.min(test.err)], importance=TRUE)
boost.fit = gbm(Salary~., data=Hitters[train,], distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[which.min(test.err)])
summary(boost.fit)
names(Hitters)
rf.hitters =  randomForest(Salary~., data = Hitters[train,], ntree=500, mtry=19)
rf.pred = predict(rf.hitters, Hitters[-train,])
mean((Hitters[-train, Salary]-rf.pred)^2)
rf.hitters =  randomForest(Salary~., data = Hitters[train,], ntree=500, mtry=19)
rf.pred = predict(rf.hitters, Hitters[-train,])
mean((Hitters[-train, Salary] - rf.pred)^2)
train
Hitters[-train, Salary]
Hitters[-train, "Salary"]
rf.hitters =  randomForest(Salary~., data = Hitters[train,], ntree=500, mtry=19)
rf.pred = predict(rf.hitters, Hitters[-train,])
mean((Hitters[-train, "Salary"] - rf.pred)^2)
set.seed(21)
rf.hitters =  randomForest(Salary~., data = Hitters[train,], ntree=500, mtry=19)
rf.pred = predict(rf.hitters, Hitters[-train,])
mean((Hitters[-train, "Salary"] - rf.pred)^2)
plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels = c(-1.8))
text(x = 1.5, y = -1, labels = c(0.63))
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x = c(0, 0), y = c(1, 2))
text(x = -1, y = 1.5, labels = c(-1.06))
text(x = 1, y = 1.5, labels = c(0.21))
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels = c(-1.8))
text(x = 1.5, y = -1, labels = c(0.63))
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x = c(0, 0), y = c(1, 2))
text(x = -1, y = 1.5, labels = c(-1.06))
text(x = 1, y = 1.5, labels = c(0.21))
par(xpd = NA)
#plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
par(xpd = NA)
plot(NA, NA, type = "n",  xlab = "X1", ylab = "X2")
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels = c(-1.8))
text(x = 1.5, y = -1, labels = c(0.63))
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x = c(0, 0), y = c(1, 2))
text(x = -1, y = 1.5, labels = c(-1.06))
text(x = 1, y = 1.5, labels = c(0.21))
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(-1, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels = c(-1.8))
text(x = 1.5, y = -1, labels = c(0.63))
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x = c(0, 0), y = c(1, 2))
text(x = -1, y = 1.5, labels = c(-1.06))
text(x = 1, y = 1.5, labels = c(0.21))
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels = c(-1.8))
text(x = 1.5, y = -1, labels = c(0.63))
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x = c(0, 0), y = c(1, 2))
text(x = -1, y = 1.5, labels = c(-1.06))
text(x = 1, y = 1.5, labels = c(0.21))
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels = c(-1.8))
text(x = 1.5, y = -1, labels = c(0.63))
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x = c(0, 0), y = c(1, 2))
text(x = -1, y = 1.5, labels = c(-1.06))
text(x = 1, y = 1.5, labels = "0.21")
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels= "-1.8")
text(x = 1.5, y = -1, labels = "0.63")
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = "2.49"))
par(xpd = NA)
plot(NA, NA, type = "n", xlim = c(-2, 2), ylim = c(-3, 3), xlab = "X1", ylab = "X2")
# X2 < 1
lines(x = c(-2, 2), y = c(1, 1))
# X1 < 1 with X2 < 1
lines(x = c(1, 1), y = c(-3, 1))
text(x = (-2 + 1)/2, y = -1, labels = c(-1.8))
text(x = 1.5, y = -1, labels = c(0.63))
# X2 < 2 with X2 >= 1
lines(x = c(-2, 2), y = c(2, 2))
text(x = 0, y = 2.5, labels = c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x = c(0, 0), y = c(1, 2))
text(x = -1, y = 1.5, labels = c(-1.06))
text(x = 1, y = 1.5, labels = c(0.21))
(/Users/rboustan/Documents/Stat202/MySolutions/hw7/IMG_2462.JPG)
